---
title: "Covid"
author: "Daniel Kim"
date: "4/21/2020"
output: html_document
---

```{r}
library(corrplot)	
library(PerformanceAnalytics)	
```

```{r}
data <- read.csv("~/Downloads/covidhospital.csv")
data1 <- data[, c(3, 4, 5, 8, 12, 13, 30, 34, 38)]
data1
data2 <- data[,c(30, 34, 38)]
```







PCA 
```{r}
qqnorm(log(data$Total.ICU.Beds))
qqnorm(data$Hospital.Bed.Occupancy.Rate)
qqnorm(data$ICU.Bed.Occupancy.Rate)
qqnorm(log(data$Available.ICU.Beds))
qqnorm(log(data$Projected.Infected.Individuals))
qqnorm(log(data$Proejcted.Hospitalized.Individuals))
qqnorm(data$Percentage.of.Total.ICU.Beds.Needed..Six.Months)
qqnorm(data$Percentage.of.Total.ICU.Beds.Needed..Twelve.Months)
qqnorm(data$Percentage.of.Total.ICU.Beds.Needed..Eighteen.Months)
```

```{r}
data2$logtotalicubed  <- log(data1$Total.ICU.Beds)
data2$logprojinfected <- log(data1$Projected.Infected.Individuals)
data2$logprojhosp <- log(data1$Proejcted.Hospitalized.Individuals)
data2$logavailicu <- log(data1$Available.ICU.Beds)
```


```{r}
source("http://www.reuningscherer.net/STAT660/R/CSQPlot.r.txt")
CSQPlot(data2,label="Hospital Data")	
```


```{r}
cor(data2)

corrplot.mixed(cor(data2), lower.col = "black", upper = "ellipse", tl.col = "black", number.cex = .7, order = "hclust", tl.pos = "lt", tl.cex = .7)	
```

```{r}
pc1 <- princomp(data2, cor = TRUE)	#creates objects
names(pc1)
print(summary(pc1), digits = 2, loadings = pc1$loadings, cutoff=0)	#gets eigenvalues
variances <- round(pc1$sdev^2,2)	#gets eigenvalues
variances 
```

```{r}
(4.99+2.32)/9
```


```{r}
screeplot(pc1 ,type="lines",col="red",lwd=2,pch=19,cex=1.2,main="Scree Plot of Hospital Data")	
```

```{r}
source("http://www.reuningscherer.net/STAT660/R/parallel.r.txt")	
parallelplot(pc1)	
```


```{r}
source("http://reuningscherer.net/stat660/r/ciscoreplot.R.txt")	
ciscoreplot(pc1,c(1,2),data[,1])	
biplot(pc1,choices=c(1,2),pc.biplot=T)	
```

```{r}
chart.Correlation(data2, histogram=TRUE, pch=19)
```



CLUSTER ANALYSIS
```{r}
covidnorm <- data[,c("Total.ICU.Beds", "Available.ICU.Beds", "Projected.Infected.Individuals", "Proejcted.Hospitalized.Individuals", "Percentage.of.Total.ICU.Beds.Needed..Six.Months", "Percentage.of.Total.ICU.Beds.Needed..Twelve.Months", "Percentage.of.Total.ICU.Beds.Needed..Eighteen.Months")]
rownames(covidnorm) <- data[,1]
covidnorm <- scale(na.omit(covidnorm)) # scaling my variables

#get the distance matrix
dist1 <- dist(covidnorm, method="euclidean")


clust1 <- hclust(dist1, )

#draw the dendrogram
plot(clust1,labels= rownames(covidnorm), cex=0.6, xlab="",ylab="Distance",main="Clustering of States Using Euclidean Distance and Complete Linkgage")
rect.hclust(clust1, k = 3)
```

```{r}
dist2 <- dist(covidnorm, method = "euclidean")
clust2 <- hclust(dist2, method = "ward.D")
plot(clust2,labels= rownames(covidnorm), cex=0.6, xlab="",ylab="Distance",main="Clustering of States Using Euclidean Distance and Ward Agglomeration")
rect.hclust(clust2, k = 3)
```

```{r}
source("http://reuningscherer.net/stat660/R/HClusEval.R.txt")
hclus_eval(covidnorm, dist_m = 'euclidean', clus_m = 'ward', plot_op = T)
```

```{r}
km1 <- kmeans(covidnorm,centers=3)
km1

for (i in 1:3){
  print(paste("Universities in Cluster ",i))
  print(data$State[km1$cluster==i])
  print (" ")
}
```

```{r}
set.seed(123)
library(factoextra)

fviz_nbclust(covidnorm, kmeans, method = "wss")
```


```{r}
kdata <- covidnorm
n.lev <- 15  #set max value for number of clusters k

# Calculate the within groups sum of squared error (SSE) for the number of cluster solutions selected by the user
wss <- rnorm(10)
while (prod(wss==sort(wss,decreasing=T))==0) {
  wss <- (nrow(kdata)-1)*sum(apply(kdata,2,var))
  for (i in 2:n.lev) wss[i] <- sum(kmeans(kdata, centers=i)$withinss)}

# Calculate the within groups SSE for 250 randomized data sets (based on the original input data)
k.rand <- function(x){
  km.rand <- matrix(sample(x),dim(x)[1],dim(x)[2])
  rand.wss <- as.matrix(dim(x)[1]-1)*sum(apply(km.rand,2,var))
  for (i in 2:n.lev) rand.wss[i] <- sum(kmeans(km.rand, centers=i)$withinss)
  rand.wss <- as.matrix(rand.wss)
  return(rand.wss)
}

rand.mat <- matrix(0,n.lev,250)

k.1 <- function(x) { 
  for (i in 1:250) {
    r.mat <- as.matrix(suppressWarnings(k.rand(kdata)))
    rand.mat[,i] <- r.mat}
  return(rand.mat)
}

# Same function as above for data with < 3 column variables
k.2.rand <- function(x){
  rand.mat <- matrix(0,n.lev,250)
  km.rand <- matrix(sample(x),dim(x)[1],dim(x)[2])
  rand.wss <- as.matrix(dim(x)[1]-1)*sum(apply(km.rand,2,var))
  for (i in 2:n.lev) rand.wss[i] <- sum(kmeans(km.rand, centers=i)$withinss)
  rand.wss <- as.matrix(rand.wss)
  return(rand.wss)
}

k.2 <- function(x){
  for (i in 1:250) {
    r.1 <- k.2.rand(kdata)
    rand.mat[,i] <- r.1}
  return(rand.mat)
}

# Determine if the data data table has > or < 3 variables and call appropriate function above
if (dim(kdata)[2] == 2) { rand.mat <- k.2(kdata) } else { rand.mat <- k.1(kdata) }

# Plot within groups SSE against all tested cluster solutions for actual and randomized data - 1st: Log scale, 2nd: Normal scale

xrange <- range(1:n.lev)
yrange <- range(log(rand.mat),log(wss))
plot(xrange,yrange, type='n', xlab='Cluster Solution', ylab='Log of Within Group SSE', main='Cluster Solutions against Log of SSE')
for (i in 1:250) lines(log(rand.mat[,i]),type='l',col='red')
lines(log(wss), type="b", col='blue')
legend('topright',c('Actual Data', '250 Random Runs'), col=c('blue', 'red'), lty=1)

```



Factor Analysis
```{r}
library(psych)
library(rela)
library(factoextra)
```

```{r}
dat <- data[,c("Total.ICU.Beds", "Available.ICU.Beds", "Projected.Infected.Individuals", "Proejcted.Hospitalized.Individuals", "Percentage.of.Total.ICU.Beds.Needed..Six.Months", "Percentage.of.Total.ICU.Beds.Needed..Twelve.Months", "Percentage.of.Total.ICU.Beds.Needed..Eighteen.Months")]
KMO(data2)
```

```{r}
covid.pca <- prcomp(data2, scale = TRUE)
fviz_eig(covid.pca)
```

```{r}
fact1 <- factanal(data2, factors = 2)
fact1

repro1 <- fact1$loadings%*%t(fact1$loadings)
repro1

resid1 <- fact1$cor-repro1
round(resid1,2)

#get root-mean squared residuals
len <- length(resid1[upper.tri(resid1)])
RMSR1 <- sqrt(sum(resid1[upper.tri(resid1)]^2)/len)
RMSR1

sum(rep(1,len)[abs(resid1[upper.tri(resid1)])>0.05])/len
```

#### Perform Factor Analysis using iterative PCA with Varimax Rotation
```{r}
#this uses the fa() function in the psych package.  Note that this fails with only 2 factors
fact2 <- fa(data2, nfactors=3, rotate="varimax", SMC=FALSE, fm="pa")
fact2

#get reproduced correlation matrix
repro2 <- fact2$loadings%*%t(fact2$loadings)
#residual correlation matrix
resid2 <- cor(data2)-repro2
round(resid2,2)

#get root-mean squared residuals - again, in output above
len <- length(resid2[upper.tri(resid2)])
RMSR3 <- sqrt(sum(resid2[upper.tri(resid2)]^2)/len)
RMSR3

#get proportion of residuals greater than 0.05 in absolute value
sum(rep(1,len)[abs(resid2[upper.tri(resid2)])>0.05])/len
```

```{r}
plot(fact2$loadings, pch=18, col='red')
abline(h=0)
abline(v=0)
text(fact2$loadings, labels=names(dat),cex=0.8)
```



